{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append 'src' directory to import modules from notebooks directory\n",
    "#################################\n",
    "import os,sys\n",
    "src_dir = os.path.join(os.getcwd(), os.pardir)\n",
    "sys.path.append(src_dir)\n",
    "##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from src.PatchMatch import PatchMatchCuda as PatchMatchOrig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_feat_map(feat_map):\n",
    "    \"\"\"\n",
    "    Normalize the feature map along the channels dimension\n",
    "    \n",
    "    feat_map is a numpy array with channels along the 2nd dimension\n",
    "    \"\"\"\n",
    "    return feat_map/np.linalg.norm(feat_map,axis=(2),keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = loadmat('../weights/imagenet-vgg-verydeep-19.mat')['layers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "convs = []\n",
    "biases = []\n",
    "\n",
    "\n",
    "for i in range(0,50):\n",
    "    try:\n",
    "        conv = mat[0][i][0][0][2][0][0] \n",
    "        bias = mat[0][i][0][0][2][0][1]\n",
    "        assert type(conv) is np.ndarray\n",
    "        assert type(bias) is np.ndarray\n",
    "        convs.append(conv)\n",
    "        biases.append(bias)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_vgg():\n",
    "        \n",
    "    with tf.variable_scope(\"VGG\"):\n",
    "\n",
    "        img = tf.placeholder(shape=[None,None,None,3],dtype=tf.float32,name='Input')\n",
    "        \n",
    "        with tf.variable_scope(\"Preprocess\"):\n",
    "            r,g,b = tf.unstack(img,axis=-1)\n",
    "            \n",
    "            b = b - 103.939\n",
    "            g = g - 116.779\n",
    "            r = r - 123.68\n",
    "            \n",
    "            img = tf.stack([b,g,r],axis=3)\n",
    "        \n",
    "\n",
    "        with tf.variable_scope(\"Conv1\"):\n",
    "            conv_1_1 = tf.layers.conv2d(inputs=img,\n",
    "                                        filters=64,\n",
    "                                        kernel_size=3,\n",
    "                                        padding='SAME',\n",
    "                                        name=\"1\",\n",
    "                                        activation=tf.nn.relu,\n",
    "                                        kernel_initializer=tf.constant_initializer(convs[0]),\n",
    "                                        bias_initializer=tf.constant_initializer(biases[0]))\n",
    "\n",
    "            conv_1_2 = tf.layers.conv2d(inputs=conv_1_1,\n",
    "                                        filters=64,\n",
    "                                        kernel_size=3,\n",
    "                                        padding='SAME',\n",
    "                                        name=\"2\",\n",
    "                                        activation=tf.nn.relu,\n",
    "                                        kernel_initializer=tf.constant_initializer(convs[1]),\n",
    "                                        bias_initializer=tf.constant_initializer(biases[1]))\n",
    "\n",
    "            mpool_1 = tf.layers.max_pooling2d(inputs=conv_1_2, padding='SAME', name='pool',pool_size=2,strides=2)\n",
    "\n",
    "        with tf.variable_scope(\"Conv2\"):\n",
    "            conv_2_1 = tf.layers.conv2d(inputs=mpool_1,\n",
    "                                        filters=128,\n",
    "                                        kernel_size=3,\n",
    "                                        padding='SAME',\n",
    "                                        name=\"1\",\n",
    "                                        activation=tf.nn.relu,\n",
    "                                        kernel_initializer=tf.constant_initializer(convs[2]),\n",
    "                                        bias_initializer=tf.constant_initializer(biases[2]))\n",
    "\n",
    "            conv_2_2 = tf.layers.conv2d(inputs=conv_2_1,\n",
    "                                        filters=128,\n",
    "                                        kernel_size=3,\n",
    "                                        padding='SAME',\n",
    "                                        name=\"2\",\n",
    "                                        activation=tf.nn.relu,\n",
    "                                        kernel_initializer=tf.constant_initializer(convs[3]),\n",
    "                                        bias_initializer=tf.constant_initializer(biases[3]))\n",
    "\n",
    "            mpool_2 = tf.layers.max_pooling2d(inputs=conv_2_2, padding='SAME', name='pool',pool_size=2,strides=2)\n",
    "\n",
    "\n",
    "        with tf.variable_scope(\"Conv3\"):\n",
    "            conv_3_1 = tf.layers.conv2d(inputs=mpool_2,\n",
    "                                        filters=256,\n",
    "                                        kernel_size=3,\n",
    "                                        padding='SAME',\n",
    "                                        name=\"1\",\n",
    "                                        activation=tf.nn.relu,\n",
    "                                        kernel_initializer=tf.constant_initializer(convs[4]),\n",
    "                                        bias_initializer=tf.constant_initializer(biases[4]))\n",
    "\n",
    "            conv_3_2 = tf.layers.conv2d(inputs=conv_3_1,\n",
    "                                        filters=256,\n",
    "                                        kernel_size=3,\n",
    "                                        padding='SAME',\n",
    "                                        name=\"2\",\n",
    "                                        activation=tf.nn.relu,\n",
    "                                        kernel_initializer=tf.constant_initializer(convs[5]),\n",
    "                                        bias_initializer=tf.constant_initializer(biases[5]))\n",
    "\n",
    "            conv_3_3 = tf.layers.conv2d(inputs=conv_3_2,\n",
    "                                        filters=256,\n",
    "                                        kernel_size=3,\n",
    "                                        padding='SAME',\n",
    "                                        name=\"3\",\n",
    "                                        activation=tf.nn.relu,\n",
    "                                        kernel_initializer=tf.constant_initializer(convs[6]),\n",
    "                                        bias_initializer=tf.constant_initializer(biases[6]))\n",
    "\n",
    "            conv_3_4 = tf.layers.conv2d(inputs=conv_3_3,\n",
    "                                        filters=256,\n",
    "                                        kernel_size=3,\n",
    "                                        padding='SAME',\n",
    "                                        name=\"4\",\n",
    "                                        activation=tf.nn.relu,\n",
    "                                        kernel_initializer=tf.constant_initializer(convs[7]),\n",
    "                                        bias_initializer=tf.constant_initializer(biases[7]))\n",
    "\n",
    "            mpool_3 = tf.layers.max_pooling2d(inputs=conv_3_4, padding='SAME', name='pool',pool_size=2,strides=2)\n",
    "\n",
    "\n",
    "\n",
    "        with tf.variable_scope(\"Conv4\"):\n",
    "            conv_4_1 = tf.layers.conv2d(inputs=mpool_3,\n",
    "                                        filters=512,\n",
    "                                        kernel_size=3,\n",
    "                                        padding='SAME',\n",
    "                                        name=\"1\",\n",
    "                                        activation=tf.nn.relu,\n",
    "                                        kernel_initializer=tf.constant_initializer(convs[8]),\n",
    "                                        bias_initializer=tf.constant_initializer(biases[8]))\n",
    "\n",
    "            conv_4_2 = tf.layers.conv2d(inputs=conv_4_1,\n",
    "                                        filters=512,\n",
    "                                        kernel_size=3,\n",
    "                                        padding='SAME',\n",
    "                                        name=\"2\",\n",
    "                                        activation=tf.nn.relu,\n",
    "                                        kernel_initializer=tf.constant_initializer(convs[9]),\n",
    "                                        bias_initializer=tf.constant_initializer(biases[9]))\n",
    "\n",
    "            conv_4_3 = tf.layers.conv2d(inputs=conv_4_2,\n",
    "                                        filters=512,\n",
    "                                        kernel_size=3,\n",
    "                                        padding='SAME',\n",
    "                                        name=\"3\",\n",
    "                                        activation=tf.nn.relu,\n",
    "                                        kernel_initializer=tf.constant_initializer(convs[10]),\n",
    "                                        bias_initializer=tf.constant_initializer(biases[10]))\n",
    "\n",
    "            conv_4_4 = tf.layers.conv2d(inputs=conv_4_3,\n",
    "                                        filters=512,\n",
    "                                        kernel_size=3,\n",
    "                                        padding='SAME',\n",
    "                                        name=\"4\",\n",
    "                                        activation=tf.nn.relu,\n",
    "                                        kernel_initializer=tf.constant_initializer(convs[11]),\n",
    "                                        bias_initializer=tf.constant_initializer(biases[11]))\n",
    "\n",
    "            mpool_4 = tf.layers.max_pooling2d(inputs=conv_4_4, padding='SAME', name='pool',pool_size=2,strides=2)\n",
    "\n",
    "\n",
    "\n",
    "        with tf.variable_scope(\"Conv5\"):\n",
    "            conv_5_1 = tf.layers.conv2d(inputs=mpool_4,\n",
    "                                        filters=512,\n",
    "                                        kernel_size=3\n",
    "                                        ,padding='SAME',\n",
    "                                        name=\"1\",\n",
    "                                        activation=tf.nn.relu,\n",
    "                                        kernel_initializer=tf.constant_initializer(convs[12]),\n",
    "                                        bias_initializer=tf.constant_initializer(biases[12]))\n",
    "\n",
    "        return conv_5_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv_block_4(conv5_1_True_NP,sess):\n",
    "        \n",
    "        with tf.variable_scope(\"Deconv_Block_4\",reuse=tf.AUTO_REUSE):\n",
    "            \n",
    "            conv5_1_True_NP = np.expand_dims(conv5_1_True_NP,axis=0)\n",
    "            \n",
    "            conv_5_1_True = tf.get_variable(name='Conv5_1_True',shape=[1,\n",
    "                                                               conv5_1_True_NP.shape[1],\n",
    "                                                               conv5_1_True_NP.shape[2],\n",
    "                                                               512])\n",
    "            \n",
    "            conv_4_1_Noise = tf.get_variable(name='conv_3_1_Noise',shape=[1,\n",
    "                                                             conv5_1_True_NP.shape[1]*2,\n",
    "                                                             conv5_1_True_NP.shape[2]*2,\n",
    "                                                             512])\n",
    "            conv_4_1_Noise_NP = np.random.randn(1,\n",
    "                                    conv5_1_True_NP.shape[1]*2,\n",
    "                                    conv5_1_True_NP.shape[2]*2,\n",
    "                                    512)*127\n",
    "\n",
    "            with tf.variable_scope(\"Conv4\",reuse=tf.AUTO_REUSE):\n",
    "\n",
    "                conv_4_2 = tf.layers.conv2d(inputs=conv_4_1_Noise,\n",
    "                                            filters=512,\n",
    "                                            kernel_size=3,\n",
    "                                            padding='SAME',\n",
    "                                            name=\"2\",\n",
    "                                            activation=tf.nn.relu,\n",
    "                                            kernel_initializer=tf.constant_initializer(convs[9]),\n",
    "                                            bias_initializer=tf.constant_initializer(biases[9]))\n",
    "\n",
    "                conv_4_3 = tf.layers.conv2d(inputs=conv_4_2,\n",
    "                                            filters=512,\n",
    "                                            kernel_size=3,\n",
    "                                            padding='SAME',\n",
    "                                            name=\"3\",\n",
    "                                            activation=tf.nn.relu,\n",
    "                                            kernel_initializer=tf.constant_initializer(convs[10]),\n",
    "                                            bias_initializer=tf.constant_initializer(biases[10]))\n",
    "\n",
    "                conv_4_4 = tf.layers.conv2d(inputs=conv_4_3,\n",
    "                                            filters=512,\n",
    "                                            kernel_size=3,\n",
    "                                            padding='SAME',\n",
    "                                            name=\"4\",\n",
    "                                            activation=tf.nn.relu,\n",
    "                                            kernel_initializer=tf.constant_initializer(convs[11]),\n",
    "                                            bias_initializer=tf.constant_initializer(biases[11]))\n",
    "\n",
    "                mpool_4 = tf.layers.max_pooling2d(inputs=conv_4_4, padding='SAME', name='pool',pool_size=2,strides=2)\n",
    "\n",
    "            with tf.variable_scope(\"Conv5\",reuse=False):\n",
    "                conv_5_1 = tf.layers.conv2d(inputs=mpool_4,\n",
    "                                            filters=512,\n",
    "                                            kernel_size=3\n",
    "                                            ,padding='SAME',\n",
    "                                            name=\"1\",\n",
    "                                            activation=tf.nn.relu,\n",
    "                                            kernel_initializer=tf.constant_initializer(convs[12]),\n",
    "                                            bias_initializer=tf.constant_initializer(biases[12]))\n",
    "\n",
    "###################################\n",
    "\n",
    "\n",
    "# Assignment ops. These are required to set the noise and True conv2_1 output to optimize for. \n",
    "# This prevent constant gpu to cpu transfer , resulting in higher performance\n",
    "\n",
    "        conv_4_1_assign_op = tf.assign(conv_4_1_Noise,\n",
    "                                       conv_4_1_Noise_NP,\n",
    "                                       validate_shape=False)\n",
    "        \n",
    "        conv_5_1_True_assign_op = tf.assign(conv_5_1_True,\n",
    "                                            conv5_1_True_NP,\n",
    "                                            validate_shape=False)\n",
    "        \n",
    "\n",
    "\n",
    "################################\n",
    "\n",
    "        loss_op = tf.losses.mean_squared_error(conv_5_1_True,\n",
    "                                               conv_5_1)\n",
    "        optim_op = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss_op,var_list=[conv_4_1_Noise])\n",
    "\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        sess.run([conv_4_1_assign_op,\n",
    "                  conv_5_1_True_assign_op])\n",
    "        \n",
    "\n",
    "        \n",
    "        optimizer = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "          var_list=[conv_4_1_Noise],\n",
    "          loss = loss_op, method='L-BFGS-B',\n",
    "          options={'disp': True})\n",
    "        optimizer.minimize(sess)\n",
    "        \n",
    "        return sess.run(conv_4_1_Noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv_block_3(conv4_1_True_NP,sess):\n",
    "        \n",
    "        with tf.variable_scope(\"Deconv_Block_3\",reuse=tf.AUTO_REUSE):\n",
    "            \n",
    "            conv4_1_True_NP = np.expand_dims(conv4_1_True_NP,axis=0)\n",
    "            conv_4_1_True = tf.get_variable(name='Conv4_1_True',shape=[1,\n",
    "                                                               conv4_1_True_NP.shape[1],\n",
    "                                                               conv4_1_True_NP.shape[2],\n",
    "                                                               512])\n",
    "            \n",
    "            conv_3_1_Noise = tf.get_variable(name='conv_3_1_Noise',shape=[1,\n",
    "                                                             conv4_1_True_NP.shape[1]*2,\n",
    "                                                             conv4_1_True_NP.shape[2]*2,\n",
    "                                                             256])\n",
    "            conv_3_1_Noise_NP = np.random.randn(1,\n",
    "                                    conv4_1_True_NP.shape[1]*2,\n",
    "                                    conv4_1_True_NP.shape[2]*2,\n",
    "                                    256)*127\n",
    "\n",
    "\n",
    "\n",
    "            with tf.variable_scope(\"Conv3\",reuse=tf.AUTO_REUSE):\n",
    "\n",
    "                conv_3_2 = tf.layers.conv2d(inputs=conv_3_1_Noise,\n",
    "                                            filters=256,\n",
    "                                            kernel_size=3,\n",
    "                                            padding='SAME',\n",
    "                                            name=\"2\",\n",
    "                                            activation=tf.nn.relu,\n",
    "                                            kernel_initializer=tf.constant_initializer(convs[5]),\n",
    "                                            bias_initializer=tf.constant_initializer(biases[5]))\n",
    "\n",
    "                conv_3_3 = tf.layers.conv2d(inputs=conv_3_2,\n",
    "                                            filters=256,\n",
    "                                            kernel_size=3,\n",
    "                                            padding='SAME',\n",
    "                                            name=\"3\",\n",
    "                                            activation=tf.nn.relu,\n",
    "                                            kernel_initializer=tf.constant_initializer(convs[6]),\n",
    "                                            bias_initializer=tf.constant_initializer(biases[6]))\n",
    "\n",
    "                conv_3_4 = tf.layers.conv2d(inputs=conv_3_3,\n",
    "                                            filters=256,\n",
    "                                            kernel_size=3,\n",
    "                                            padding='SAME',\n",
    "                                            name=\"4\",\n",
    "                                            activation=tf.nn.relu,\n",
    "                                            kernel_initializer=tf.constant_initializer(convs[7]),\n",
    "                                            bias_initializer=tf.constant_initializer(biases[7]))\n",
    "\n",
    "                mpool_3 = tf.layers.max_pooling2d(inputs=conv_3_4, padding='SAME', name='pool',pool_size=2,strides=2)\n",
    "\n",
    "\n",
    "\n",
    "            with tf.variable_scope(\"Conv4\",reuse=tf.AUTO_REUSE):\n",
    "                conv_4_1 = tf.layers.conv2d(inputs=mpool_3,\n",
    "                                            filters=512,\n",
    "                                            kernel_size=3,\n",
    "                                            padding='SAME',\n",
    "                                            name=\"1\",\n",
    "                                            activation=tf.nn.relu,\n",
    "                                            kernel_initializer=tf.constant_initializer(convs[8]),\n",
    "                                            bias_initializer=tf.constant_initializer(biases[8]))\n",
    "\n",
    "###################################\n",
    "\n",
    "\n",
    "# Assignment ops. These are required to set the noise and True conv2_1 output to optimize for. \n",
    "# This prevent constant gpu to cpu transfer , resulting in higher performance\n",
    "\n",
    "        conv_3_1_assign_op = tf.assign(conv_3_1_Noise,\n",
    "                                       conv_3_1_Noise_NP,\n",
    "                                       validate_shape=False)\n",
    "        \n",
    "        conv_4_1_True_assign_op = tf.assign(conv_4_1_True,\n",
    "                                            conv4_1_True_NP,\n",
    "                                            validate_shape=False)\n",
    "        \n",
    "\n",
    "\n",
    "################################\n",
    "\n",
    "        loss_op = tf.losses.mean_squared_error(conv_4_1_True,\n",
    "                                               conv_4_1)\n",
    "        optim_op = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss_op,var_list=[conv_3_1_Noise])\n",
    "\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        sess.run([conv_3_1_assign_op,\n",
    "                  conv_4_1_True_assign_op])\n",
    "        \n",
    "\n",
    "        \n",
    "        optimizer = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "          var_list=[conv_3_1_Noise],\n",
    "          loss = loss_op, method='L-BFGS-B',\n",
    "          options={'disp': True})\n",
    "        optimizer.minimize(sess)\n",
    "        \n",
    "        return sess.run(conv_3_1_Noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv_block_2(conv3_1_True_NP,sess):\n",
    "\n",
    "    with tf.variable_scope(\"Deconv_Block_2\",reuse=tf.AUTO_REUSE):\n",
    "        \n",
    "        conv3_1_True_NP = np.expand_dims(conv3_1_True_NP,axis=0)\n",
    "        conv_3_1_True = tf.get_variable(name='Conv3_1_True',shape=[1,\n",
    "                                                           conv3_1_True_NP.shape[1],\n",
    "                                                           conv3_1_True_NP.shape[2],\n",
    "                                                           256])\n",
    "        conv_2_1_Noise = tf.get_variable(name='conv_2_1_Noise',shape=[1,\n",
    "                                                         conv3_1_True_NP.shape[1]*2,\n",
    "                                                         conv3_1_True_NP.shape[2]*2,\n",
    "                                                         128])\n",
    "        conv_2_1_Noise_NP = np.random.randn(1,\n",
    "                                conv3_1_True_NP.shape[1]*2,\n",
    "                                conv3_1_True_NP.shape[2]*2,\n",
    "                                128)*127\n",
    "################# Sub VGG###################\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "        with tf.variable_scope(\"Conv2\",reuse=tf.AUTO_REUSE):\n",
    "\n",
    "            conv_2_2 = tf.layers.conv2d(inputs=conv_2_1_Noise,\n",
    "                                            filters=128,\n",
    "                                            kernel_size=3,\n",
    "                                            padding='SAME',\n",
    "                                            name=\"2\",\n",
    "                                            activation=tf.nn.relu,\n",
    "                                            kernel_initializer=tf.constant_initializer(convs[3]),\n",
    "                                            bias_initializer=tf.constant_initializer(biases[3]))\n",
    "\n",
    "            mpool_2 = tf.layers.max_pooling2d(inputs=conv_2_2, padding='SAME', name='pool',pool_size=2,strides=2)\n",
    "\n",
    "\n",
    "        with tf.variable_scope(\"Conv3\",reuse=tf.AUTO_REUSE):\n",
    "            conv_3_1 = tf.layers.conv2d(inputs=mpool_2,\n",
    "                                        filters=256,\n",
    "                                        kernel_size=3,\n",
    "                                        padding='SAME',\n",
    "                                        name=\"1\",\n",
    "                                        activation=tf.nn.relu,\n",
    "                                        kernel_initializer=tf.constant_initializer(convs[4]),\n",
    "                                        bias_initializer=tf.constant_initializer(biases[4]))\n",
    "            \n",
    "            \n",
    "###################################\n",
    "\n",
    "\n",
    "# Assignment ops. These are required to set the noise and True conv2_1 output to optimize for. \n",
    "# This prevent constant gpu to cpu transfer , resulting in higher performance\n",
    "\n",
    "        conv_2_1_assign_op = tf.assign(conv_2_1_Noise,\n",
    "                                       conv_2_1_Noise_NP,\n",
    "                                       validate_shape=False)\n",
    "        \n",
    "        conv_3_1_True_assign_op = tf.assign(conv_3_1_True,\n",
    "                                            conv3_1_True_NP,\n",
    "                                            validate_shape=False)\n",
    "        \n",
    "\n",
    "\n",
    "################################\n",
    "\n",
    "        loss_op = tf.losses.mean_squared_error(conv_3_1_True,\n",
    "                                               conv_3_1)\n",
    "        optim_op = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss_op,var_list=[conv_2_1_Noise])\n",
    "\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        sess.run([conv_2_1_assign_op,\n",
    "                  conv_3_1_True_assign_op])\n",
    "        \n",
    "\n",
    "        \n",
    "        optimizer = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "          var_list=[conv_2_1_Noise],\n",
    "          loss = loss_op, method='L-BFGS-B',\n",
    "          options={'disp': True})\n",
    "        optimizer.minimize(sess)\n",
    "        \n",
    "        return sess.run(conv_2_1_Noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv_block_1(conv2_1_True_NP,sess):\n",
    "    with tf.variable_scope(\"Deconv_Block_1\",reuse=tf.AUTO_REUSE):\n",
    "        \n",
    "        conv2_1_True_NP = np.expand_dims(conv2_1_True_NP,axis=0)\n",
    "        conv_2_1_True = tf.get_variable(name='Conv2_1_True',shape=[1,\n",
    "                                                           conv2_1_True_NP.shape[1],\n",
    "                                                           conv2_1_True_NP.shape[2],\n",
    "                                                           128])\n",
    "        conv_1_1_Noise = tf.get_variable(name='conv_1_1_Noise',shape=[1,\n",
    "                                                         conv2_1_True_NP.shape[1]*2,\n",
    "                                                         conv2_1_True_NP.shape[2]*2,\n",
    "                                                         64])\n",
    "        conv_1_1_Noise_NP = np.random.randn(1,\n",
    "                                conv2_1_True_NP.shape[1]*2,\n",
    "                                conv2_1_True_NP.shape[2]*2,\n",
    "                                64)*127\n",
    "################# Sub VGG###################\n",
    "        with tf.variable_scope(\"Conv1\",reuse=tf.AUTO_REUSE):\n",
    "            conv_1_2 = tf.layers.conv2d(inputs=conv_1_1_Noise,\n",
    "                                        filters=64,\n",
    "                                        kernel_size=3,\n",
    "                                        padding='SAME',\n",
    "                                        name=\"2\",\n",
    "                                        activation=tf.nn.relu,\n",
    "                                        kernel_initializer=tf.constant_initializer(convs[1]),\n",
    "                                        bias_initializer=tf.constant_initializer(biases[1]))\n",
    "\n",
    "            mpool_1 = tf.layers.max_pooling2d(inputs=conv_1_2,\n",
    "                                              padding='SAME',\n",
    "                                              name='pool',\n",
    "                                              pool_size=2,\n",
    "                                              strides=2)\n",
    "\n",
    "        with tf.variable_scope(\"Conv2\",reuse=tf.AUTO_REUSE):\n",
    "            conv_2_1 = tf.layers.conv2d(inputs=mpool_1,\n",
    "                                        filters=128,\n",
    "                                        kernel_size=3,\n",
    "                                        padding='SAME',\n",
    "                                        name=\"1\",\n",
    "                                        activation=tf.nn.relu,\n",
    "                                        kernel_initializer=tf.constant_initializer(convs[2]),\n",
    "                                        bias_initializer=tf.constant_initializer(biases[2]))\n",
    "###################################\n",
    "\n",
    "\n",
    "\n",
    "# Assignment ops. These are required to set the noise and True conv2_1 output to optimize for. \n",
    "# This prevent constant gpu to cpu transfer , resulting in higher performance\n",
    "\n",
    "        conv_1_1_assign_op = tf.assign(conv_1_1_Noise,\n",
    "                                       conv_1_1_Noise_NP,\n",
    "                                       validate_shape=False)\n",
    "        \n",
    "        conv_2_1_True_assign_op = tf.assign(conv_2_1_True,\n",
    "                                            conv2_1_True_NP,\n",
    "                                            validate_shape=False)\n",
    "\n",
    "################################\n",
    "\n",
    "        loss_op = tf.losses.mean_squared_error(conv_2_1_True,\n",
    "                                               conv_2_1)\n",
    "        optim_op = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss_op,var_list=[conv_1_1_Noise])\n",
    "\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        sess.run([conv_1_1_assign_op,\n",
    "                  conv_2_1_True_assign_op])\n",
    "        \n",
    "        optimizer = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "          var_list=[conv_1_1_Noise],\n",
    "          loss = loss_op, method='L-BFGS-B',\n",
    "          options={'disp': True})\n",
    "        optimizer.minimize(sess)\n",
    "        \n",
    "        return sess.run(conv_1_1_Noise)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = np.array(Image.open('../data/raw/ava.png').convert('RGB').resize((224,224)),dtype=np.float32)\n",
    "img1 = np.expand_dims(img1,axis=0)\n",
    "\n",
    "img2 = np.array(Image.open('../data/raw/mona.png').convert('RGB').resize((224,224)),dtype=np.float32)\n",
    "img2 = np.expand_dims(img2,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession(graph=tf.Graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_conv = prepare_vgg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 17.311647\n",
      "  Number of iterations: 175\n",
      "  Number of functions evaluations: 186\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "output1 = sess.run('VGG/Conv5/1/Relu:0',feed_dict={'VGG/Input:0':img1})\n",
    "\n",
    "TEST = deconv_block_4(output1.squeeze(),sess)\n",
    "\n",
    "writer = tf.summary.FileWriter(\"../logs\",sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INFO:tensorflow:Optimization terminated with:\n",
    "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
    "  Objective function value: 3.889272\n",
    "  Number of iterations: 249\n",
    "  Number of functions evaluations: 259"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 56, 56, 256)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c0353e3c5b07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "output = output.squeeze()\n",
    "output1 = output1.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feata = normalize_feat_map(output)\n",
    "feataa = normalize_feat_map(output)\n",
    "\n",
    "featb = normalize_feat_map(output1)\n",
    "featbb = normalize_feat_map(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm5ab = PatchMatchOrig(feata,feataa,featb,featbb, 3)\n",
    "# plt.imshow(pm5ab.visualize())\n",
    "pm5ab.propagate(iters=5,rand_search_radius=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = pm5ab.reconstruct_image(img1)\n",
    "recon = np.ndarray.astype(recon,np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w=10\n",
    "h=10\n",
    "fig=plt.figure(figsize=(16, 512//4))\n",
    "columns = 8\n",
    "rows = 512//8\n",
    "for i in range(1, columns*rows +1):\n",
    "    img = output[:,:,i-1]\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img,cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[conv.shape for conv in convs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_variable('ok',shape=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "v = None\n",
    "with tf.variable_scope(\"\",reuse=tf.AUTO_REUSE):\n",
    "    v = tf.get_variable('ok',shape=[1,2,3])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run('Deconv_Block_1/Input:0').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run('Deconv_Block_1/Conv2_1_True:0').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    v = tf.Variable(name='ok',initial_value=[1,2,3])\n",
    "sess.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[n.name for n in tf.get_default_graph().as_graph_def().node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randn(112,112,128)*10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(TEST[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output[:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess.run(tf.global_variables_initializer())\n",
    "TEST.minimize(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 56, 56, 256)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
