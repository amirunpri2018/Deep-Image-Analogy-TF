{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import cv2\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "# import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageOps\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path, to_array=False, to_variable=False):\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img = ImageOps.fit(img, (224,224), Image.ANTIALIAS)\n",
    "\n",
    "    scale = transforms.Scale((224,224))\n",
    "    tensorize = transforms.ToTensor()\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    loader = transforms.Compose([\n",
    "        scale, tensorize, normalize\n",
    "    ])\n",
    "    img_tensor = loader(img)\n",
    "\n",
    "    if to_array:\n",
    "        img_tensor = img_tensor.unsqueeze(0)\n",
    "    if to_variable:\n",
    "        img_tensor = Variable(img_tensor)\n",
    "\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "\n",
    "    def add_layer(self, name, layer):\n",
    "        self.add_module(name, layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        list = []\n",
    "        for module in self._modules:\n",
    "            x = self._modules[module](x)\n",
    "            list.append(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class VGG19:\n",
    "    def __init__(self,use_cuda=True):\n",
    "        self.cnn_temp = models.vgg19(pretrained=True).features\n",
    "        self.model = FeatureExtractor()  # the new Feature extractor module network\n",
    "        conv_counter = 1\n",
    "        relu_counter = 1\n",
    "        batn_counter = 1\n",
    "\n",
    "        block_counter = 1\n",
    "        self.use_cuda = use_cuda\n",
    "\n",
    "        for i, layer in enumerate(list(self.cnn_temp)[:-1]):\n",
    "\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                name = \"conv_\" + str(block_counter) + \"_\" + str(conv_counter) + \"__\" + str(i)\n",
    "                conv_counter += 1\n",
    "                self.model.add_layer(name, layer)\n",
    "\n",
    "            if isinstance(layer, nn.ReLU):\n",
    "                name = \"relu_\" + str(block_counter) + \"_\" + str(relu_counter) + \"__\" + str(i)\n",
    "                relu_counter += 1\n",
    "                self.model.add_layer(name, nn.ReLU(inplace=False))\n",
    "\n",
    "            if isinstance(layer, nn.MaxPool2d):\n",
    "                name = \"pool_\" + str(block_counter) + \"__\" + str(i)\n",
    "                batn_counter = relu_counter = conv_counter = 1\n",
    "                block_counter += 1\n",
    "                self.model.add_layer(name, nn.AvgPool2d((2,2)))  # ***\n",
    "\n",
    "\n",
    "            if isinstance(layer, nn.BatchNorm2d):\n",
    "                name = \"batn_\" + str(block_counter) + \"_\" + str(batn_counter) + \"__\" + str(i)\n",
    "                batn_counter += 1\n",
    "                self.model.add_layer(name, layer)  # ***\n",
    "        \n",
    "        self.model.add_layer(\"deconv_1\",nn.ConvTranspose2d(512,512,3,padding=1,stride=2,output_padding=1))\n",
    "        self.model.add_layer(\"relu_1\",nn.ReLU())\n",
    "        \n",
    "        self.model.add_layer(\"deconv_2\",nn.ConvTranspose2d(512,256,3,padding=1,stride=2,output_padding=1))\n",
    "        self.model.add_layer(\"relu_2\",nn.ReLU())\n",
    "        \n",
    "        self.model.add_layer(\"deconv_3\",nn.ConvTranspose2d(256,128,3,padding=1,stride=2,output_padding=1))\n",
    "        self.model.add_layer(\"relu_3\",nn.ReLU())\n",
    "        \n",
    "        self.model.add_layer(\"deconv_4\",nn.ConvTranspose2d(128,64,3,padding=1,stride=2,output_padding=1))\n",
    "        self.model.add_layer(\"relu_4\",nn.ReLU())\n",
    "        \n",
    "        self.model.add_layer(\"deconv_5\",nn.ConvTranspose2d(64,3,3,padding=1,stride=1))\n",
    "        self.model.add_layer(\"relu_5\",nn.Tanh())\n",
    "        \n",
    "        if use_cuda:\n",
    "            self.model.cuda()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = VGG19()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureExtractor (\n",
       "  (conv_1_1__0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_1_1__1): ReLU ()\n",
       "  (conv_1_2__2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_1_2__3): ReLU ()\n",
       "  (pool_1__4): AvgPool2d (size=(2, 2), stride=(2, 2), padding=0, ceil_mode=False, count_include_pad=True)\n",
       "  (conv_2_1__5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_2_1__6): ReLU ()\n",
       "  (conv_2_2__7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_2_2__8): ReLU ()\n",
       "  (pool_2__9): AvgPool2d (size=(2, 2), stride=(2, 2), padding=0, ceil_mode=False, count_include_pad=True)\n",
       "  (conv_3_1__10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_3_1__11): ReLU ()\n",
       "  (conv_3_2__12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_3_2__13): ReLU ()\n",
       "  (conv_3_3__14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_3_3__15): ReLU ()\n",
       "  (conv_3_4__16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_3_4__17): ReLU ()\n",
       "  (pool_3__18): AvgPool2d (size=(2, 2), stride=(2, 2), padding=0, ceil_mode=False, count_include_pad=True)\n",
       "  (conv_4_1__19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_4_1__20): ReLU ()\n",
       "  (conv_4_2__21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_4_2__22): ReLU ()\n",
       "  (conv_4_3__23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_4_3__24): ReLU ()\n",
       "  (conv_4_4__25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_4_4__26): ReLU ()\n",
       "  (pool_4__27): AvgPool2d (size=(2, 2), stride=(2, 2), padding=0, ceil_mode=False, count_include_pad=True)\n",
       "  (conv_5_1__28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_5_1__29): ReLU ()\n",
       "  (conv_5_2__30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_5_2__31): ReLU ()\n",
       "  (conv_5_3__32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_5_3__33): ReLU ()\n",
       "  (conv_5_4__34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_5_4__35): ReLU ()\n",
       "  (deconv_1): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (relu_1): ReLU ()\n",
       "  (deconv_2): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (relu_2): ReLU ()\n",
       "  (deconv_3): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (relu_3): ReLU ()\n",
       "  (deconv_4): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (relu_4): ReLU ()\n",
       "  (deconv_5): ConvTranspose2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_5): Tanh ()\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_image('../data/raw/mona.png',to_array=True,to_variable=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "( 0 , 0 ,.,.) = \n",
       "  0.6563  0.8447  0.8276  ...   0.7933  1.9749  2.2489\n",
       "  0.7248  0.7762  0.8104  ...   0.8276  1.9749  2.2489\n",
       "  0.8104  0.8447  0.7077  ...   0.8789  1.9920  2.2489\n",
       "           ...             ⋱             ...          \n",
       " -0.1999 -0.2684 -0.3027  ...  -1.3130  1.5982  2.2489\n",
       "  1.9235  1.9064  1.8893  ...   1.7694  2.1633  2.2489\n",
       "  2.2489  2.2489  2.2489  ...   2.2489  2.2489  2.2489\n",
       "\n",
       "( 0 , 1 ,.,.) = \n",
       "  0.3277  0.5028  0.4503  ...   0.2227  2.0259  2.4286\n",
       "  0.3803  0.4328  0.4153  ...   0.2752  2.0259  2.4286\n",
       "  0.4853  0.5203  0.3452  ...   0.3627  2.0259  2.4286\n",
       "           ...             ⋱             ...          \n",
       " -0.3550 -0.4251 -0.4426  ...  -1.3880  1.7283  2.4286\n",
       "  2.0434  2.0434  2.0434  ...   1.9034  2.3410  2.4286\n",
       "  2.4286  2.4286  2.4286  ...   2.4286  2.4286  2.4286\n",
       "\n",
       "( 0 , 2 ,.,.) = \n",
       " -0.7587 -0.5844 -0.6367  ...  -0.7064  2.0125  2.6400\n",
       " -0.7413 -0.6890 -0.6890  ...  -0.7238  2.0125  2.6400\n",
       " -0.7064 -0.6715 -0.8284  ...  -0.7238  2.0125  2.6400\n",
       "           ...             ⋱             ...          \n",
       " -0.5321 -0.5844 -0.6193  ...  -1.1770  1.9428  2.6400\n",
       "  2.2043  2.1868  2.1868  ...   2.1171  2.5529  2.6400\n",
       "  2.6400  2.6400  2.6400  ...   2.6400  2.6400  2.6400\n",
       "[torch.cuda.FloatTensor of size 1x3x224x224 (GPU 0)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = m.model(img).data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.03628633, -0.03260871, -0.03260176, ..., -0.03261039,\n",
       "          -0.03250055, -0.03337964],\n",
       "         [-0.03494947, -0.03174857, -0.02974411, ..., -0.03158811,\n",
       "          -0.02972015, -0.03009969],\n",
       "         [-0.03374782, -0.03183108, -0.03107746, ..., -0.031876  ,\n",
       "          -0.03149058, -0.03048148],\n",
       "         ..., \n",
       "         [-0.03476657, -0.03177645, -0.02966691, ..., -0.03166542,\n",
       "          -0.0295557 , -0.03006133],\n",
       "         [-0.03367876, -0.0318023 , -0.03166504, ..., -0.03163098,\n",
       "          -0.03172738, -0.03065073],\n",
       "         [-0.03472697, -0.03260031, -0.03116279, ..., -0.03261478,\n",
       "          -0.03122886, -0.03063195]],\n",
       "\n",
       "        [[-0.03937261, -0.03767584, -0.03730569, ..., -0.0373462 ,\n",
       "          -0.03680017, -0.03513333],\n",
       "         [-0.0361164 , -0.0311667 , -0.02957006, ..., -0.03129539,\n",
       "          -0.02946368, -0.02907613],\n",
       "         [-0.03737508, -0.03105266, -0.03161094, ..., -0.03062549,\n",
       "          -0.0309506 , -0.02991763],\n",
       "         ..., \n",
       "         [-0.03612369, -0.03138725, -0.02946698, ..., -0.03116821,\n",
       "          -0.02963828, -0.02919569],\n",
       "         [-0.03708061, -0.02989368, -0.0313012 , ..., -0.02999938,\n",
       "          -0.03093361, -0.02929054],\n",
       "         [-0.0412351 , -0.03906973, -0.03817626, ..., -0.03907242,\n",
       "          -0.03816382, -0.03591203]],\n",
       "\n",
       "        [[ 0.03632946,  0.03558819,  0.03508969, ...,  0.03549653,\n",
       "           0.03589455,  0.02699121],\n",
       "         [ 0.04328388,  0.04432777,  0.04543508, ...,  0.04424683,\n",
       "           0.04497551,  0.0319235 ],\n",
       "         [ 0.04106266,  0.04339834,  0.0426062 , ...,  0.04309398,\n",
       "           0.04397847,  0.03034149],\n",
       "         ..., \n",
       "         [ 0.04313703,  0.04427702,  0.0454775 , ...,  0.04434979,\n",
       "           0.04505056,  0.03189708],\n",
       "         [ 0.04113193,  0.04326867,  0.0426844 , ...,  0.0431273 ,\n",
       "           0.04364127,  0.03019091],\n",
       "         [ 0.03868855,  0.04183143,  0.04193309, ...,  0.04182111,\n",
       "           0.0419315 ,  0.03409628]]]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(m.model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss  = nn.MSELoss(size_average=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.87364435]\n",
      "[ 1.85647869]\n",
      "[ 1.34267128]\n",
      "[ 1.36963916]\n",
      "[ 1.39013219]\n",
      "[ 1.26115012]\n",
      "[ 1.55644989]\n",
      "[ 1.34805405]\n",
      "[ 1.40232158]\n",
      "[ 1.40411985]\n",
      "[ 1.40284681]\n",
      "[ 1.40119803]\n",
      "[ 1.40114248]\n",
      "[ 1.39207792]\n",
      "[ 1.3823024]\n",
      "[ 1.38273525]\n",
      "[ 1.39135849]\n",
      "[ 1.38538766]\n",
      "[ 1.38680589]\n",
      "[ 1.3868165]\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    output = m.model(img)\n",
    "    loss_val = loss(output,img)\n",
    "    loss_val.backward()\n",
    "    optimizer.step()\n",
    "    print(loss_val.data.cpu().numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = m.model(img).data.cpu().squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  1.], dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa08c0b64a8>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKUjqMClI6jApSOr4fxciiZZ3KgcaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa07feda518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(t.transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-9c094877f8c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "t.squeeze().numpy().transpose(1,2,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(img.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
